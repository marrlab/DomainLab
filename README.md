# M-HOF-Opt: Multi-Objective Hierarchical Output Feedback Optimization via Multiplier Induced Loss Landscape Scheduling
When a neural network parameterized loss con-
sists of many terms, the combinatorial choice
of weight multipliers during the optimization
process forms a challenging problem. To ad-
dress this, we proposed a probabilistic graphi-
cal model (PGM) for the joint model param-
eter and multiplier evolution process, with a
hypervolume based likelihood that promotes
multi-objective descent of each loss term. The
corresponding parameter and multiplier esti-
mation as a sequential decision process is then
cast into an optimal control problem, where
the multi-objective descent goal is dispatched
hierarchically into a series of constraint opti-
mization sub-problems. The subproblem con-
straint automatically adapts itself according
to Pareto dominance and serves as the set-
point for the low level multiplier controller to
schedule loss landscapes via output feedback of
each loss term. Our method is multiplier-free
and operates at the timescale of epochs, thus
saves dramatic computational resources com-
pared to full training cycle multiplier tuning.
We applied it to domain invariant variational
auto-encoding with 6 loss terms on the PACS
domain generalization task, and observed ro-
bust performance across a range of controller
hyperparameters, as well as different multiplier
initial conditions, outperforming other multi-
plier scheduling methods. We offered modular
implementation of our method a admitting cus-
tom definition of many loss terms for applying
our multi-objective hierarchical output feed-
back training scheme to other deep learning
fields.

M-HOF-Opt is implemented in [DomainLab](https://github.com/marrlab/DomainLab). If you meet any problems, feel free to report them at https://github.com/marrlab/DomainLab/issues

## Dependencies and Data Preparation
#### Example dependencies installation
```
git checkout mhof  # switch to mhof branch
conda create --name domainlab_py39 python=3.9  # create a virtual environment
conda activate domainlab_py39  # activate virtual environment
conda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=11.6 -c pytorch -c conda-forge
conda install torchmetrics==0.10.3
pip install -r requirements_notorch.txt
conda install tensorboard # install tensorboard
```

#### Data preparation: download the domain generalization dataset PACS

step 1:

use the following script to download PACS to your local laptop and upload it to your cluster

https://github.com/marrlab/DomainLab/blob/fbopt/data/script/download_pacs.py

step 2:
make a symbolic link following the example script in https://github.com/marrlab/DomainLab/blob/master/sh_pacs.sh

where `mkdir -p data/pacs` is executed under the repository directory,

`ln -s /dir/to/yourdata/pacs/raw  ./data/pacs/PACS`
will create a symbolic link under the repository directory

### M-HOF experiments reproduction

#### Run the experiment

To execute a single run of the M-HOF method, from the root folder run the command:

```
python main_out.py -c a_reproduce_pacs_diva.yaml
```

which uses the configuration file [a_reproduce_pacs_diva.yaml](https://github.com/marrlab/DomainLab/blob/mhof/a_reproduce_pacs_diva.yaml).

#### Visualization of the results

The results of the experiment are stored in the `runs` directory generated by Tensorboard.
The various loss curves with the corresponding setpoint change curves, as well as phase-portrait-like figures showing the loss dynamics between the task loss and the various regularization losses, can be obtained by running the script [script_generate_all_figures_diva.sh](https://github.com/marrlab/DomainLab/blob/mhof/script_generate_all_figures_diva.sh):

```
bash script_generate_all_figures_diva.sh
```

The resulting figures will be stored in the directory `figures_diva`, which can be changed by editing the top of the [script_generate_all_figures_diva.sh](https://github.com/marrlab/DomainLab/blob/mhof/script_generate_all_figures_diva.sh) file if needed.
