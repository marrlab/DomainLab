# only entries related to parameter sampling
output_dir: "zoutput/benchmarks/hyperparameter_test"
num_param_samples: 30

# currently, everything which contains the aname property is considered as a task.
Task1:  # name
  aname: Algo1
  # Each parameter must contain:
  # - distribution
  # - min and max if distribution is uniform or loguniform
  # - mean and std if distribution is normal or lognormal
  # OR
  # reference, use this for equality constraints.
  hyperparameters:
    p1:
      distribution: uniform    # uniform | loguniform | normal | lognormal
      min: 1  # in case of uniform
      max: 3  # in case of uniform
      step: 0    # anything > 0 for discrete variables, 0 for continuous ones. Optional

    p2:
      distribution: normal
      mean: 1 # in case of normal
      std: 2  # in case of normal
      step: 1 # integer valued

    p3:
      min: 1e-6
      max: 1
      distribution: loguniform
      step: 0

    p4:
      # Value of p4 will always equal p3.
      # Note that references to references are not supported
      # and result in undefined behaviour.
      reference: p3

    # Optional
    constraints:
      # In this list, any valid Python code evaluating to bool can be used.
      # The parameters can be accessed by their name from above.
      # Note that equality constraints should not be posed here,
      # but enforced through references.
      # Otherwise, the sampling will abort with error in most cases.
      - "p1 < p2"
      - "p3 < p2"

Task2:  # name
  aname: Algo2

  hyperparameters:
    p1:
      mean: 1
      std: 3
      step: 2   # only odd numbers
      distribution: lognormal

    p2:
      min: -2
      max: 2
      step: 1
      distribution: uniform

Task3:
  aname: Algo3
  zd_dim: 5