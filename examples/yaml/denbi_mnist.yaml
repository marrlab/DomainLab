# test benchmark config.

# dataset
task: mnistcolor10

test_domains:
  - 3

output_dir: zoutput/benchmarks/mnist_benchmark503
dmem: False
te_d:
  - 0
  - 1
  - 2

lr: 0.001

# number of hyperparameter samples per task.
# Thus, the total runs of each task are given
# by len(domains) * num_param_samples * num_seeds (see below)
num_param_samples: 8
sampling_seed: 503

epos: 50
es: 5
bs: 64
startseed: 1
endseed: 1  # currently included

# set all parameters to default first
nname: conv_bn_pool_2
#lr: 1e-4
#gamma_reg: 0.1
#es: 10
#gen: False
#split: 0
#san_check: False
#zd_dim: 64
#zx_dim: 0
#zy_dim: 64

Task1:  # name
  aname: diva
  # set nname_dom = nname when changing nname
  nname_dom: conv_bn_pool_2

  hyperparameters:
    gamma_y:
      min: 1e4
      max: 2e5
      step: 100
      distribution: loguniform

    gamma_d:
      min: 1e4
      max: 1e6
      step: 10_000
      distribution: loguniform

    zx_dim:
      min: 0
      max: 96
      step: 32
      distribution: uniform

    zy_dim:
      min: 32
      max: 96
      step: 32
      distribution: uniform

    zd_dim:
      reference: zy_dim

    gamma_reg:
      min: 0.01
      max: 10
      distribution: loguniform

Task2:  # name
  aname: hduva

  nname_topic_distrib_img2topic: conv_bn_pool_2
  nname_encoder_sandwich_layer_img2h4zd: conv_bn_pool_2

  hyperparameters:
    # Same config as diva.
    gamma_y:
      min: 1e4
      max: 2e5
      step: 100
      distribution: loguniform

    zx_dim:
      min: 0
      max: 96
      step: 32
      distribution: uniform

    zy_dim:
      min: 32
      max: 96
      step: 32
      distribution: uniform

    zd_dim:
      reference: zy_dim

    gamma_reg:
      min: 0.01
      max: 10
      distribution: loguniform

Task3:  # name
  aname: matchdg

  hyperparameters:
    # penalty weight for matching loss (Lambda in paper)
    penalty_ws:
      min: 0.01
      max: 10
      distribution: loguniform

    # Total number of epochs for contrastive loss
    epochs_ctr:
      min: 2
      max: 10
      step: 1
      distribution: uniform

    # this shall be set to be epos - epochs_ctr
    # as epos cannot be referenced here one needs to hardcode this right number of epos here
    epochs_erm:
      reference: max(1, 50 - epochs_ctr)

    # factor to magnify cosine similarity
    tau:
      min: 0.01
      max: 1
      distribution: loguniform

    # Number of epochs before updating the match tensor
    epos_per_match_update:
      min: 1
      max: 20
      step: 1
      distribution: uniform

    gamma_reg:
      min: 0.01
      max: 10
      distribution: loguniform

Task4:  # name
  aname: jigen
  grid_len: 3

  hyperparameters:
    # number of permutations
    nperm:
      distribution: categorical
      values:
        - 30
        - 31
        - 100
      datatype: int

    # probability of permutating the tiles of an image, pperm = 0 -> pure classification
    pperm:
      min: 0.1
      max: 0.5
      distribution: uniform

    gamma_reg:
      min: 0.01
      max: 10
      distribution: loguniform


Task5:  # name
  aname: dann

  hyperparameters:
    early_stop:
      distribution: categorical
      datatype: int
      values:
        - 1
        - 5
        - 10

    gamma_reg:
      min: 0.01
      max: 10
      distribution: loguniform

Task6:  # name
  aname: deepall

  hyperparameters:

    gamma_reg:
      min: 0.01
      max: 10
      distribution: loguniform

Task7: # name
  aname: deepall_dial

  hyperparameters:
    dial_steps_perturb:
      min: 1
      max: 10
      step: 1
      distribution: uniform

    dial_noise_scale:
      min: 0.00001
      max: 0.1
      distribution: loguniform

    dial_epsilon:
      min: 0.001
      max: 0.01
      distribution: loguniform

    gamma_reg:
      min: 0.01
      max: 10
      distribution: loguniform
